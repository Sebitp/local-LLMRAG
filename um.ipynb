{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmbm119/370RAG/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/nmbm119/370RAG/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: multiplying in assembly\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # choose the device to load the model to\n",
    "# 1. define a query\n",
    "query = \"multiplying in assembly\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (we'll time this for fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time take to get scores on 2253 embeddings: 0.00121 seconds.\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.6652, 0.6641, 0.6588, 0.6531, 0.6528], device='cuda:0'),\n",
      "indices=tensor([560, 538, 542, 207, 540], device='cuda:0'))\n",
      "{'page_number': 318, 'chunk': '3.11 Concluding Remarks  245 A math professor at Lynchburg College in Virginia, Thomas Nicely, discovered  the bug in September 1994. After calling Intel technical support and getting no  official reaction, he posted his discovery on the Internet. This post led to a story  in a trade magazine, which in turn caused Intel to issue a press release. It called  the bug a glitch that would affect only theoretical mathematicians, with the  average spreadsheet user seeing an error every 27,000 years. IBM Research soon  counterclaimed that the average spreadsheet user would see an error every 24  days. Intel soon threw in the towel by making the following announcement on  December 21: We at Intel wish to sincerely apologize for our handling of the recently publicized  Pentium processor flaw. The Intel Inside symbol means that your computer has  a microprocessor second to none in quality and performance. Thousands of Intel  employees work very hard to ensure that this is true. But no microprocessor is  ever perfect. What Intel continues to believe is technically an extremely minor  problem has taken on a life of its own.', 'chunk_char_count': 1128, 'chunk_word_count': 197, 'chunk_token_count': 282.0, 'embedding': array([-3.28543968e-03, -4.79028486e-02, -2.86045857e-02,  3.85122185e-05,\n",
      "       -1.15538510e-02,  1.70855541e-02,  4.70490707e-03,  4.03845496e-02,\n",
      "        2.72773858e-03,  5.31384628e-03,  6.03942126e-02,  1.75467823e-02,\n",
      "        5.69882318e-02, -7.96629116e-03,  1.88019425e-02,  4.59693968e-02,\n",
      "        9.02736709e-02,  1.10773128e-02, -1.14012230e-02,  1.89792775e-02,\n",
      "       -3.81775275e-02, -6.44836156e-03,  2.98446766e-03,  8.80040228e-03,\n",
      "       -3.03418357e-02, -1.68302990e-02,  4.21637222e-02,  1.24844499e-02,\n",
      "       -2.60438155e-02, -1.02385366e-02, -3.73928957e-02, -7.15142861e-02,\n",
      "       -4.04656231e-02,  1.09170107e-02,  2.26787142e-06,  3.54600488e-03,\n",
      "       -1.73047818e-02,  5.74313253e-02, -3.82335186e-02,  6.84706122e-02,\n",
      "       -3.88755836e-02, -5.79905463e-03, -1.05106561e-02,  1.13616977e-02,\n",
      "        3.27290632e-02,  1.00736106e-02, -2.46720947e-02,  4.07235958e-02,\n",
      "       -4.99093086e-02, -3.67162935e-02,  5.53310150e-03,  1.11970171e-01,\n",
      "        9.00358409e-02, -1.22478120e-02,  6.14414848e-02, -5.60902618e-02,\n",
      "        1.62567099e-04, -4.97789048e-02, -7.18417158e-03, -1.75062921e-02,\n",
      "        3.42543214e-03,  7.79739115e-03,  3.15722334e-03,  2.51710527e-02,\n",
      "       -4.98913527e-02,  2.46738293e-03,  1.51074193e-02, -2.74292603e-02,\n",
      "       -7.83770625e-03, -2.20809057e-02, -1.43857887e-02,  2.04276089e-02,\n",
      "        1.15615185e-02,  2.98037492e-02, -2.87221260e-02, -6.19207658e-02,\n",
      "        6.13008849e-02, -5.30036576e-02, -6.02533668e-02, -7.68106431e-02,\n",
      "        7.02528581e-02,  1.66771822e-02,  2.58016605e-02, -3.70401628e-02,\n",
      "        2.65311915e-02,  6.12343512e-02, -9.76310484e-03, -5.77201471e-02,\n",
      "        2.83402670e-03,  3.79244201e-02, -1.92670021e-02,  2.15627272e-02,\n",
      "       -3.99712939e-03, -4.47675101e-02,  6.11191578e-02,  3.04395128e-02,\n",
      "       -5.95708787e-02,  1.96926817e-02,  1.48104096e-03, -5.32650724e-02,\n",
      "        2.89201271e-02,  2.59783827e-02,  4.76771928e-02, -2.52489876e-02,\n",
      "        5.01114829e-03, -4.39836551e-03, -5.25124408e-02, -3.17786844e-03,\n",
      "        2.78383046e-02,  8.28455836e-02,  4.59052511e-02,  3.11048012e-02,\n",
      "        3.81693430e-02,  3.63290869e-03,  4.97244485e-02,  3.05074546e-02,\n",
      "        4.67117205e-02,  3.63940969e-02, -4.57056127e-02,  8.02144557e-02,\n",
      "       -3.12847570e-02, -4.29673754e-02, -4.45629619e-02, -1.27049498e-02,\n",
      "       -3.02784294e-02, -1.13966651e-02,  1.66132394e-02, -4.63348739e-02,\n",
      "       -3.64798866e-02, -7.90585652e-02, -3.78324203e-02, -5.44338748e-02,\n",
      "       -3.50390002e-02,  5.28031169e-03, -5.27764251e-03,  2.49533076e-02,\n",
      "       -4.36225813e-03,  1.75068807e-02,  1.16086630e-02, -8.54098517e-03,\n",
      "       -4.17931788e-02,  4.94233100e-03, -3.64925563e-02,  2.21939590e-02,\n",
      "       -1.67890470e-02,  1.12129496e-02,  3.72352637e-02,  2.04159375e-02,\n",
      "        2.89017987e-02,  6.57140017e-02, -6.06266782e-02,  1.48703419e-02,\n",
      "       -1.08588502e-01,  1.62126264e-03, -5.23749087e-03,  5.62363677e-02,\n",
      "        3.16865668e-02, -4.18249033e-02,  1.18360121e-03, -5.57875447e-02,\n",
      "        2.18474455e-02,  1.31533323e-02,  1.07931634e-02, -3.28821838e-02,\n",
      "        6.25354722e-02,  1.21636325e-02,  6.69258088e-02,  2.33451463e-02,\n",
      "       -4.62360755e-02, -7.95036368e-03, -4.27382514e-02,  2.39296220e-02,\n",
      "        3.92743573e-02, -8.19767447e-05, -3.66549231e-02,  7.32196076e-03,\n",
      "       -4.55026701e-02,  3.57552953e-02, -6.13469146e-02,  1.57997757e-02,\n",
      "       -1.82847567e-02, -2.75537763e-02, -1.32597834e-02, -9.70284862e-04,\n",
      "       -3.77372801e-02, -5.29651949e-03, -5.40165420e-05, -1.61581151e-02,\n",
      "       -2.10982971e-02, -2.48541087e-02, -1.34878932e-02,  1.22191953e-02,\n",
      "       -6.05283901e-02, -2.20744056e-03,  1.55683998e-02, -1.34973861e-02,\n",
      "        2.24211589e-02, -2.74590729e-03,  3.71648837e-03,  1.87969189e-02,\n",
      "       -2.14488059e-02, -6.42723069e-02,  7.38184601e-02,  8.39785039e-02,\n",
      "       -1.11924121e-02, -1.62193167e-03, -1.43171120e-02, -3.75445634e-02,\n",
      "       -3.08980849e-02, -5.47127202e-02,  3.05377599e-02,  1.39908036e-02,\n",
      "       -2.78464127e-02,  5.30635845e-03,  2.09267847e-02,  6.60343189e-03,\n",
      "       -1.74972992e-02,  4.56139306e-03, -4.12806608e-02,  4.66702692e-02,\n",
      "       -1.04917353e-02, -3.07331383e-02,  5.24887145e-02, -2.16403604e-02,\n",
      "       -6.94275834e-03, -9.81025584e-03,  1.55099621e-02, -2.29377691e-02,\n",
      "       -4.81855907e-02,  1.60279814e-02, -1.55848609e-02,  6.10588212e-03,\n",
      "        1.55601082e-02,  3.20989899e-02,  9.20540094e-03, -5.55249676e-03,\n",
      "       -1.08209886e-01,  3.10685881e-03,  2.47741994e-02, -1.31780067e-02,\n",
      "       -1.33857448e-02,  1.44651835e-03,  6.92150416e-03,  4.94252937e-03,\n",
      "        7.14600533e-02, -6.93091080e-02, -7.73119368e-03,  5.47058694e-03,\n",
      "        1.11133531e-02, -3.93319763e-02,  1.25830492e-03,  2.76795458e-02,\n",
      "       -4.73964727e-03, -2.07254272e-02,  6.85688388e-03,  4.91681683e-04,\n",
      "        1.80326756e-02,  1.41801611e-02, -5.99576272e-02, -1.76278856e-02,\n",
      "        4.22665961e-02, -1.07366720e-03,  2.06028651e-02, -4.03855368e-02,\n",
      "       -1.53008113e-02,  2.65406389e-02,  1.76924691e-02, -5.25361598e-02,\n",
      "       -1.18809706e-02,  2.03444678e-02, -1.43497726e-02,  9.32028797e-03,\n",
      "       -3.99029776e-02, -5.33186132e-03, -2.49446779e-02,  3.83010767e-02,\n",
      "       -2.37018336e-02,  1.97469015e-02, -9.58518870e-03,  2.23255716e-02,\n",
      "        1.52883073e-02, -2.42854040e-02,  6.14730921e-03, -5.64109907e-02,\n",
      "       -2.84625068e-02,  1.10849151e-02,  4.42334786e-02, -1.69305708e-02,\n",
      "       -5.68168908e-02,  3.03133447e-02,  8.36128462e-03, -2.16924865e-03,\n",
      "        7.64145190e-03,  7.51216710e-02, -1.59694795e-02, -1.06846048e-02,\n",
      "       -3.41922371e-03,  7.63556734e-02, -2.67962664e-02,  1.43658444e-01,\n",
      "       -6.32564649e-02, -1.35056227e-02, -2.51886863e-02,  1.67545751e-02,\n",
      "        3.92788164e-02,  8.51241220e-03,  3.73109393e-02, -2.34126877e-02,\n",
      "       -2.07788553e-02,  1.80463842e-03, -4.92842449e-03, -7.98814371e-03,\n",
      "       -8.46550334e-03,  2.78801899e-02, -3.94558860e-03,  1.64577551e-02,\n",
      "        3.84787731e-02, -1.67170893e-02,  1.71681382e-02,  2.62017697e-02,\n",
      "       -6.60128519e-02, -2.16545872e-02,  1.77203976e-02, -1.58176403e-02,\n",
      "       -9.30985715e-03, -3.83783169e-02,  3.75891151e-03,  3.31327133e-02,\n",
      "       -1.65805053e-02, -7.11675361e-02, -3.18581611e-02, -3.02490462e-02,\n",
      "       -1.86529662e-02,  2.29109377e-02,  1.66504551e-02, -1.75978225e-02,\n",
      "       -3.08914445e-02,  5.55454604e-02,  6.87906239e-03, -4.28608852e-03,\n",
      "       -1.74350813e-02, -1.90715939e-02,  4.32357118e-02, -8.55738530e-04,\n",
      "       -6.35705050e-03, -5.41340709e-02,  7.77173117e-02, -1.83246247e-02,\n",
      "        8.53977352e-03, -8.05749074e-02,  8.10144022e-02, -3.07089202e-02,\n",
      "       -9.23125446e-03, -5.82729392e-02,  1.12570683e-02, -7.41838366e-02,\n",
      "       -2.71702390e-02, -5.96852526e-02,  4.17584367e-02,  1.42680295e-03,\n",
      "        3.52397822e-02,  9.29695833e-03,  7.14617893e-02,  4.44976017e-02,\n",
      "       -1.92814022e-02,  2.08665915e-02,  2.61610672e-02,  1.86086725e-02,\n",
      "       -4.88502458e-02,  1.95678510e-02, -2.13213880e-02,  4.75854427e-03,\n",
      "       -3.84941213e-02, -5.38084619e-02, -3.62882651e-02,  2.72839889e-02,\n",
      "        5.76464552e-03,  4.92345840e-02,  1.50784198e-02,  3.96651812e-02,\n",
      "        1.90831926e-02, -2.63064671e-02,  1.24189341e-02,  3.78326587e-02,\n",
      "        1.75205693e-02, -3.33326310e-02, -2.31761485e-02,  6.99828658e-03,\n",
      "       -5.83562702e-02,  3.08380425e-02, -8.38830043e-03,  6.23881556e-02,\n",
      "       -3.19117419e-02, -2.18126476e-02,  2.25152373e-02,  2.64064483e-02,\n",
      "        6.80135936e-02,  9.62960999e-03, -4.05734554e-02,  5.31302728e-02,\n",
      "        2.16931868e-02, -4.92207520e-02,  7.62402499e-03,  2.11165547e-02,\n",
      "        4.74605821e-02, -1.43995471e-02,  1.10445386e-02, -3.59043255e-02,\n",
      "       -4.61221822e-02, -7.18823588e-03,  2.49368344e-02,  2.72013750e-02,\n",
      "        3.25117931e-02, -2.06613857e-02,  1.02362730e-01, -3.18267122e-02,\n",
      "       -1.20825376e-02, -3.68370116e-02, -7.61884451e-02, -4.22295704e-02,\n",
      "        6.88340813e-02,  3.74220777e-03,  2.80648470e-02, -7.85093009e-03,\n",
      "        1.77088119e-02, -6.70198863e-03, -1.17740147e-02, -2.38610376e-02,\n",
      "       -3.82150151e-02, -2.94466801e-02, -4.20995895e-03, -5.01634367e-02,\n",
      "       -7.24121276e-03,  5.12995198e-02, -4.61985990e-02,  3.15340050e-02,\n",
      "       -1.45346737e-02,  6.78399717e-03, -4.22394276e-02,  3.08854971e-02,\n",
      "       -2.11170204e-02, -1.88716184e-02,  4.49337624e-02,  1.27137527e-02,\n",
      "       -6.70195520e-02, -2.48318110e-02,  2.35183761e-02, -5.59001826e-02,\n",
      "       -1.56515837e-02,  2.06239074e-02,  4.69101444e-02,  1.55919660e-02,\n",
      "        8.98889303e-02, -4.70824987e-02,  5.20180948e-02, -2.40241271e-03,\n",
      "        8.88466910e-02, -3.59847397e-02, -2.45152749e-02, -8.00181087e-03,\n",
      "        7.80440569e-02,  2.20521465e-02, -4.30097058e-03, -2.18694247e-02,\n",
      "        6.37549609e-02, -2.98856460e-02, -3.89356492e-03,  5.78506477e-03,\n",
      "        3.36169302e-02, -2.22387146e-02, -7.26412609e-02,  3.08103040e-02,\n",
      "       -2.52095144e-02, -1.61339052e-03, -1.02719910e-01,  1.68589633e-02,\n",
      "       -1.31111676e-02, -4.28206399e-02, -2.63852421e-02, -1.99173503e-02,\n",
      "        1.73858870e-02,  4.00114385e-03,  4.32029776e-02,  2.19427235e-02,\n",
      "        5.85828070e-03, -5.36351791e-03, -2.09113900e-02,  8.12591054e-03,\n",
      "       -6.09448552e-03,  2.70862342e-03,  3.55358562e-03, -2.78083347e-02,\n",
      "       -3.65929827e-02,  2.03583818e-02,  3.38170305e-02,  2.31677722e-02,\n",
      "        1.38327898e-02,  2.57415138e-03, -2.63093766e-02,  8.01695436e-02,\n",
      "        1.66555904e-02,  1.96336079e-02,  2.54076300e-03,  5.70341907e-02,\n",
      "       -8.00217595e-03,  2.23084502e-02,  1.54241510e-02,  1.90396514e-02,\n",
      "       -7.47208018e-03,  8.52073915e-03,  3.03325336e-02, -3.63065116e-03,\n",
      "       -4.89468165e-02, -6.45372570e-02,  3.55898216e-02,  5.98016195e-03,\n",
      "        6.68280991e-05,  2.59646922e-02, -9.69862845e-03,  4.41996194e-02,\n",
      "       -7.37870438e-03,  5.24149789e-03,  7.06242910e-03, -1.10077681e-02,\n",
      "       -2.53516901e-02, -3.27139199e-02,  6.84106676e-03, -3.26343663e-02,\n",
      "       -5.45005722e-04, -9.41060018e-03, -5.61123118e-02, -1.64282843e-02,\n",
      "       -3.14970464e-02, -1.70224551e-02,  2.60948297e-02,  1.53969908e-02,\n",
      "       -1.71689503e-03,  3.65573587e-03,  4.38674167e-02, -7.02825263e-02,\n",
      "        1.85917388e-03, -4.19039391e-02,  7.23524615e-02, -1.18530840e-02,\n",
      "        3.01164594e-02, -3.27996910e-02, -1.03766704e-02,  5.05004413e-02,\n",
      "        2.35169772e-02, -7.04970434e-02,  3.21429931e-02,  2.12579332e-02,\n",
      "       -5.63018844e-02,  1.12825064e-02, -1.56503450e-02, -6.20812289e-33,\n",
      "       -2.32517477e-02,  1.29627215e-03, -5.18065840e-02,  7.23119974e-02,\n",
      "       -1.39997182e-02,  4.45112446e-03,  2.04756819e-02,  1.62245687e-02,\n",
      "        6.07003644e-03, -1.87023375e-02, -3.79616953e-02,  4.80683818e-02,\n",
      "        2.41574030e-02, -1.67299435e-02, -2.42888331e-02, -4.30709869e-02,\n",
      "        3.05681564e-02,  2.22202688e-02,  5.35010472e-02,  1.29107889e-02,\n",
      "       -1.44543871e-02,  2.57792678e-02, -1.88724585e-02, -4.07294035e-02,\n",
      "        2.84186136e-02, -1.82300769e-02,  6.65431563e-03, -3.12764533e-02,\n",
      "       -1.22442460e-02, -7.97705073e-03,  3.87818068e-02, -1.72079708e-02,\n",
      "       -3.57302348e-03, -6.33303262e-03, -1.37156863e-02, -3.73499542e-02,\n",
      "       -3.12063545e-02, -3.45919700e-03, -1.69250108e-02,  2.74555734e-03,\n",
      "        3.40864733e-02, -1.23020597e-02,  8.15084297e-03,  1.75810605e-02,\n",
      "       -2.22887211e-02, -1.95987616e-02,  2.62253415e-02, -8.64144042e-03,\n",
      "       -1.70385297e-02, -4.76869754e-02,  6.11325130e-02, -2.15491299e-02,\n",
      "        1.04047982e-02,  5.55343702e-02, -6.07807748e-02, -2.39642151e-03,\n",
      "        1.81476045e-02, -5.37661090e-02, -2.78569944e-02, -1.78800803e-02,\n",
      "        1.05542261e-02, -2.47987686e-03,  2.32898165e-02,  8.43173417e-04,\n",
      "        1.08316063e-03, -1.24623743e-03,  9.07886177e-02,  8.93280208e-02,\n",
      "       -1.33004580e-02, -9.22542904e-03,  4.56477925e-02, -3.36747803e-02,\n",
      "       -9.11425054e-03,  2.99121514e-02,  5.08818822e-03, -6.81610182e-02,\n",
      "        4.47224855e-04,  4.81925830e-02,  2.54004588e-03, -2.52075084e-02,\n",
      "       -2.24086232e-02, -4.65535596e-02, -9.87293497e-02, -4.51422818e-02,\n",
      "        4.38938476e-02,  4.44661863e-02, -2.53779367e-02, -2.61207949e-02,\n",
      "        4.14135307e-02, -3.00819129e-02,  1.01424098e-01,  1.37114242e-01,\n",
      "       -4.39607626e-04, -1.43009936e-02,  3.89419720e-02, -5.70245497e-02,\n",
      "        3.05976011e-02,  1.56481750e-02, -4.04043235e-02, -8.60063732e-03,\n",
      "       -4.40722443e-02, -3.42373364e-02, -7.77291805e-02,  3.62549238e-02,\n",
      "        2.22967714e-02,  1.70785841e-02,  2.01065931e-02,  4.65844525e-03,\n",
      "       -4.74395044e-02,  1.69597305e-02,  2.62410734e-02,  1.67225376e-02,\n",
      "        2.88549662e-02,  3.41529783e-04, -1.05451299e-02,  2.72476748e-02,\n",
      "       -2.12648939e-02, -4.16108817e-02,  2.50447225e-02,  9.14332569e-02,\n",
      "       -3.36361378e-02, -5.33825159e-02, -7.05664158e-02,  4.29840907e-02,\n",
      "        4.21053283e-02,  6.66700676e-03, -2.01477204e-02,  8.02602898e-03,\n",
      "       -3.39911021e-02, -3.93990874e-02, -2.00335272e-02, -1.19139887e-02,\n",
      "        3.05007717e-07, -1.61051508e-02,  3.21197584e-02,  4.45108339e-02,\n",
      "       -5.75781949e-02, -1.69873927e-02, -2.51744706e-02, -3.40950601e-02,\n",
      "        3.22036371e-02,  4.29399647e-02,  4.01883647e-02,  4.55301218e-02,\n",
      "        1.14494842e-02,  2.27869116e-02, -3.38616669e-02,  5.98920956e-02,\n",
      "        5.89891663e-03, -7.93215260e-03,  1.43929953e-02, -2.92453934e-02,\n",
      "        2.93290522e-02,  4.21978235e-02, -4.98918295e-02,  7.54149258e-03,\n",
      "        1.90274362e-02,  2.00191364e-02, -7.28760883e-02,  2.44350936e-02,\n",
      "       -7.51356333e-02, -3.31198014e-02,  2.03590351e-03,  4.21800166e-02,\n",
      "        7.20198750e-02, -2.91341770e-04,  4.07713465e-02,  4.60625812e-03,\n",
      "       -5.19572571e-02,  1.48744965e-02,  1.62375439e-02,  3.04536000e-02,\n",
      "        4.84006293e-02, -2.69240849e-02, -5.70762828e-02,  1.24500543e-02,\n",
      "       -3.23865237e-03,  1.43819442e-02,  5.94781898e-02, -2.67674535e-04,\n",
      "        4.31880169e-02,  8.88066180e-03, -1.68018625e-03, -3.23902234e-04,\n",
      "        1.96569990e-02,  3.32648046e-02, -3.50148231e-03,  4.38718498e-03,\n",
      "        1.78088807e-02,  2.99845170e-03, -4.08688886e-03, -1.78942420e-02,\n",
      "        4.41870652e-02, -6.31601885e-02, -4.92421426e-02,  3.05037666e-02,\n",
      "       -1.50560010e-02,  6.78086979e-03,  1.40601797e-02, -3.93304788e-02,\n",
      "        3.26789702e-34,  8.80151615e-03, -5.58232963e-02,  3.28140557e-02,\n",
      "       -4.87618670e-02,  9.81227681e-03,  1.21441437e-02,  6.34148866e-02,\n",
      "       -3.81832421e-02, -7.70129915e-03,  2.68993080e-02, -5.06806374e-02])}\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "print(top_results_dot_product)\n",
    "print(pages_and_chunks[643])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'multiplying in assembly'\n",
      "\n",
      "Results:\n",
      "Score: 0.6652\n",
      "Text:\n",
      "LEGv8 assembly language Category  Instruction Example Meaning Comments\n",
      "Arithmetic add  ADD    X1, X2, X3 SUB    X1, X2, X3 ADDI   X1, X2, 20 SUBI   X1,\n",
      "X2, 20 ADDS   X1, X2, X3 SUBS   X1, X2, X3 ADDIS  X1, X2, 20 SUBIS  X1, X2, 20\n",
      "LDUR   X1, [X2,40] X1 = X2 + X3 X1 = X2 – X3 X1 = X2 + 20 X1 = X2 – 20 X1 = X2 +\n",
      "X3 X1 = X2 – X3 X1 = X2 + 20 X1 = X2 – 20 Subtract constant, set condition codes\n",
      "Three register operands subtract Three register operands add immediate Used to\n",
      "add constants subtract immediate Used to subtract constants add and set flags\n",
      "Add, set condition codes subtract and set flags Subtract, set condition codes\n",
      "add immediate and set  flags Add constant, set condition codes subtract\n",
      "immediate and  set flags multiply MUL    X1, X2, X3 X1 = X2 × X3 Lower 64-bits\n",
      "of 128-bit product signed multiply high SMULH  X1, X2, X3 X1 = X2 × X3 Upper\n",
      "64-bits of 128-bit signed product unsigned multiply high UMULH  X1, X2, X3 X1 =\n",
      "X2 × X3 Upper 64-bits of 128-bit unsigned product signed divide SDIV   X1, X2,\n",
      "X3 X1 = X2 / X3 Divide, treating operands as signed unsigned divide UDIV   X1,\n",
      "X2, X3 X1 = X2 / X3 Divide, treating operands as unsigned Data transfer  load\n",
      "register Doubleword from memory to register store register STUR   X1, [X2,40]\n",
      "LDURSW X1, [X2,40] Doubleword from register to memory load signed word Word from\n",
      "memory to register store word STURW  X1, [X2,40] LDURH  X1, [X2,40] Word from\n",
      "register to memory  load half Halfword memory to register store half STURH  X1,\n",
      "[X2,40] LDURB  X1, [X2,40] Halfword register to memory load byte Byte from\n",
      "memory to register store byte STURB  X1, [X2,40] LDXR   X1, [X2,0] STXR   X1,\n",
      "X3, [X2] Byte from register to memory load exclusive register Load; 1st half of\n",
      "atomic swap store exclusive register Store; 2nd half of atomic swap move wide\n",
      "with zero Loads 16-bit constant, rest zeros  MOVZ   X1,20 X1 = Memory[X2 + 40]\n",
      "Memory[X2 + 40] = X1 X1 = Memory[X2 + 40] Memory[X2 + 40] = X1 X1 = Memory[X2 +\n",
      "40] Memory[X2 + 40] = X1 X1 = Memory[X2 + 40] Memory[X2 + 40] = X1 X1 =\n",
      "Memory[X2] Memory[X2]=X1;X3=0 or 1 X1 = 20 or 20 * 216 or 20 * 232 or 20 * 248\n",
      "Logical and Three reg. operands; bit-by-bit AND inclusive or Three reg.\n",
      "operands; bit-by-bit OR exclusive or Three reg. operands; bit-by-bit XOR and\n",
      "immediate Bit-by-bit AND reg with constant inclusive or immediate Bit-by-bit OR\n",
      "reg with constant exclusive or immediate Bit-by-bit XOR reg with constant\n",
      "logical shift left Shift left by constant Condi- tional  branch compare and\n",
      "branch on equal 0 if (X1 == 0) go to PC +  4 + 100 Equal 0 test; PC-relative\n",
      "branch branch conditionally B.cond 25 if (condition true) go to PC + 4 + 100\n",
      "Test condition codes; if true, branch Uncondi- tional    jump branch B      2500\n",
      "go to PC + 4 + 10000 Branch to target address; PC-relative branch to register BR\n",
      "X30 go to X30 For switch, procedure return branch with link BL     2500 X30 = PC\n",
      "+ 4; PC + 4 + 10000 For procedure call PC-relative logical shift right AND\n",
      "X1, X2, X3 ORR    X1, X2, X3 EOR    X1, X2, X3 ANDI   X1, X2, 20 ORRI   X1, X2,\n",
      "20 EORI   X1, X2, 20 LSL    X1, X2, 10 LSR    X1, X2, 10 CBZ    X1, 25 compare\n",
      "and branch on  not equal 0 if (X1!= 0) go to PC +  4 + 100 Not equal 0 test; PC-\n",
      "relative CBNZ   X1, 25 X1 = X2 & X3 X1 = X2 | X3 X1 = X2 ^ X3 X1 = X2 & 20 X1 =\n",
      "X2 | 20 X1 = X2 ^ 20 X1 = X2 << 10 X1 = X2 >> 10 Shift right by constant move\n",
      "wide with keep Loads 16-bit constant, rest unchanged MOVK   X1,20 X1 = 20 or 20\n",
      "* 216 or 20 * 232 or 20 * 248 FIGURE 3.12 LEGv8 core architecture. LEGv8 machine\n",
      "language is listed in the LEGv8 Reference Data Card at the front of this book.\n",
      "Page number: 277\n",
      "\n",
      "\n",
      "Score: 0.6641\n",
      "Text:\n",
      "3.3 Multiplication  193 Multiplicand Shift left 128 bits 128-bit ALU Product\n",
      "Write 128 bits Control test Multiplier Shift right 64 bits FIGURE 3.3 First\n",
      "version of the multiplication hardware. The Multiplicand register, ALU, and\n",
      "Product register are all 128 bits wide, with only the Multiplier register\n",
      "containing 64 bits. ( Appendix A  describes ALUs.) The 64-bit multiplicand\n",
      "starts in the right half of the Multiplicand register and is shifted left  1 bit\n",
      "on each step. The multiplier is shifted in the opposite direction at each step.\n",
      "The algorithm starts with  the product initialized to 0. Control decides when to\n",
      "shift the Multiplicand and Multiplier registers and when  to write new values\n",
      "into the Product register. Figure 3.4 shows the three basic steps needed for\n",
      "each bit. The least significant  bit of the multiplier (Multiplier0) determines\n",
      "whether the multiplicand is added to  the Product register. The left shift in\n",
      "step 2 has the effect of moving the intermediate  operands to the left, just as\n",
      "when multiplying with paper and pencil.\n",
      "Page number: 266\n",
      "\n",
      "\n",
      "Score: 0.6588\n",
      "Text:\n",
      "3.3 Multiplication  195 Multiplicand 64 bits 64-bit ALU Product Write 128 bits\n",
      "Control test Shift right FIGURE 3.5 Refined version of the multiplication\n",
      "hardware. Compare with the first version in  Figure 3.3. The Multiplicand\n",
      "register, ALU, and Multiplier register are all 64 bits wide, with only the\n",
      "Product  register left at 128 bits. Now the product is shifted right. The\n",
      "separate Multiplier register also disappeared. The  multiplier is placed instead\n",
      "in the right half of the Product register. These changes are highlighted in\n",
      "color.  (The Product register should really be 129 bits to hold the carry out of\n",
      "the adder, but it’s shown here as 128  bits to highlight the evolution from\n",
      "Figure 3.3.) A Multiply Algorithm Using 4-bit numbers to save space, multiply\n",
      "2ten × 3ten, or 0010two × 0011two. Figure 3.6 shows the value of each register\n",
      "for each of the steps labeled  according to Figure 3.4, with the final value of\n",
      "0000 0110two or 6ten.\n",
      "Page number: 268\n",
      "\n",
      "\n",
      "Score: 0.6531\n",
      "Text:\n",
      "64  Chapter 2 Instructions: Language of the Computer LEGv8 operands Name Example\n",
      "Comments 32 registers X0–X30, XZR Fast locations for data. In LEGv8, data must\n",
      "be in registers to perform arithmetic, register XZR always equals 0. 262 memory\n",
      "words Memory[0], Memory[4], . . . ,  Memory[4,611,686,018,427,387, 904] Accessed\n",
      "only by data transfer instructions. LEGv8 uses byte addresses, so sequential\n",
      "doubleword addresses differ by 8. Memory holds data structures,  arrays, and\n",
      "spilled registers. LEGv8 assembly language Category InstructionExample Meaning\n",
      "Comments add ADD   X1, X2, X3 Three register operands subtract SUB   X1, X2, X3\n",
      "Three register operands add immediate ADDI  X1, X2, 20 Used to add constants\n",
      "Arithmetic Data transfer subtract immediate SUBI  X1, X2, 20 Used to subtract\n",
      "constants add and set flags ADDS  X1, X2, X3 Add, set condition codes subtract\n",
      "and set flags SUBS  X1, X2, X3 Subtract, set condition codes add immediate and\n",
      "set flags ADDIS X1, X2, 20 Add constant, set condition codes subtract immediate\n",
      "and set flags SUBIS X1, X2, 20 X1 = X2 + X3 X1 = X2 — X3 X1 = X2 + 20 X1 = X2 —\n",
      "20 X1 = X2 + X3 X1 = X2 — X3 X1 = X2 + 20 X1 = X2 — 20 Subtract constant, set\n",
      "condition  codes load register LDUR  X1, [X2,40] Doubleword from memory to\n",
      "register X1 = Memory[X2 + 40] store register STUR  X1, [X2,40] Doubleword from\n",
      "register to  memory Memory[X2 + 40] = X1 load signed word LDURSW X1,[X2,40] Word\n",
      "from memory to register store word STURW X1, [X2,40] Word from register to\n",
      "memory load half LDURH X1, [X2,40] Halfword memory to register X1 = Memory[X2 +\n",
      "40] Memory[X2 + 40] = X1 X1 = Memory[X2 + 40] store half STURH X1, [X2,40]\n",
      "Halfword register to memory load byte LDURB X1, [X2,40] Byte from memory to\n",
      "register store byte STURB X1, [X2,40] Byte from register to memory load\n",
      "exclusive  register LDXR  X1, [X2,0] Load; 1st half of atomic swap store\n",
      "exclusive  register Memory[X2 + 40] = X1 X1 = Memory[X2 + 40] Memory[X2 + 40] =\n",
      "X1 X1 = Memory[X2] STXR  X1, X3 [X2] Store; 2nd half of atomic swap Loads 16-bit\n",
      "constant, rest zeros  Loads 16-bit constant, rest unchanged Memory[X2]=X1;X3=0\n",
      "or 1 move wide with zero MOVZ X1,20, LSL 0 X1 = 20 or 20 * 216 or 20 * 232 or 20\n",
      "* 248 move wide with keep MOVK X1,20, LSL 0 X1 = 20 or 20 * 216 or 20 * 232 or\n",
      "20 * 248 FIGURE 2.1 LEGv8 assembly language revealed in this chapter. This\n",
      "information is also found in Column 1 of the LEGv8  Reference Data Card at the\n",
      "front of this book.\n",
      "Page number: 102\n",
      "\n",
      "\n",
      "Score: 0.6528\n",
      "Text:\n",
      "194  Chapter 3 Arithmetic for Computers 32nd repetition? 1a.  Add multiplicand\n",
      "to product and place the result in Product register Multiplier0 = 0 1.  Test\n",
      "Multiplier0 Start Multiplier0 = 1 2.  Shift the Multiplicand register left 1 bit\n",
      "3.  Shift the Multiplier register right 1 bit No: < 64 repetitions Yes: 64\n",
      "repetitions Done FIGURE 3.4 The first multiplication algorithm, using the\n",
      "hardware shown in Figure 3.3. If the  least significant bit of the multiplier is\n",
      "1, add the multiplicand to the product. If not, go to the next step. Shift the\n",
      "multiplicand left and the multiplier right in the next two steps. These three\n",
      "steps are repeated 64 times.\n",
      "Page number: 267\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2253 embeddings: 0.00014 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.6795, 0.6775, 0.6687, 0.6631, 0.6619], device='cuda:0'),\n",
       " tensor([540, 681, 682, 539, 536], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"efficient multiplication\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2253 embeddings: 0.00010 seconds.\n",
      "Query: efficient multiplication\n",
      "\n",
      "Results:\n",
      "Score: 0.6795\n",
      "194  Chapter 3 Arithmetic for Computers 32nd repetition? 1a.  Add multiplicand\n",
      "to product and place the result in Product register Multiplier0 = 0 1.  Test\n",
      "Multiplier0 Start Multiplier0 = 1 2.  Shift the Multiplicand register left 1 bit\n",
      "3.  Shift the Multiplier register right 1 bit No: < 64 repetitions Yes: 64\n",
      "repetitions Done FIGURE 3.4 The first multiplication algorithm, using the\n",
      "hardware shown in Figure 3.3. If the  least significant bit of the multiplier is\n",
      "1, add the multiplicand to the product. If not, go to the next step. Shift the\n",
      "multiplicand left and the multiplier right in the next two steps. These three\n",
      "steps are repeated 64 times.\n",
      "Page number: 267\n",
      "\n",
      "\n",
      "Score: 0.6775\n",
      "250  Chapter 3 Arithmetic for Computers 3.13 [20] <§3.3> Using a table similar\n",
      "to that shown in Figure 3.6, calculate the  product of the hexadecimal unsigned\n",
      "8-bit integers 62 and 12 using the hardware  described in Figure 3.5. You should\n",
      "show the contents of each register on each step. 3.14 [10] <§3.3> Calculate the\n",
      "time necessary to perform a multiply using the  approach given in Figures 3.3\n",
      "and 3.4 if an integer is 8 bits wide and each step of  the operation takes four\n",
      "time units. Assume that in step 1a an addition is always  performed—either the\n",
      "multiplicand will be added, or a zero will be. Also assume  that the registers\n",
      "have already been initialized (you are just counting how long it  takes to do\n",
      "the multiplication loop itself). If this is being done in hardware, the  shifts\n",
      "of the multiplicand and multiplier can be done simultaneously. If this is being\n",
      "done in software, they will have to be done one after the other. Solve for each\n",
      "case. 3.15 [10] <§3.3> Calculate the time necessary to perform a multiply using\n",
      "the  approach described in the text (31 adders stacked vertically) if an integer\n",
      "is 8 bits  wide and an adder takes four time units. 3.16 [20] <§3.3> Calculate\n",
      "the time necessary to perform a multiply using the  approach given in Figure 3.7\n",
      "if an integer is 8 bits wide and an adder takes four  time units.\n",
      "Page number: 333\n",
      "\n",
      "\n",
      "Score: 0.6687\n",
      "3.17 [20] <§3.3> As discussed in the text, one possible performance enhancement\n",
      "is  to do a shift and add instead of an actual multiplication. Since 9 × 6, for\n",
      "example, can  be written (2 × 2 × 2 + 1) × 6, we can calculate 9 × 6 by shifting\n",
      "6 to the left three times  and then adding 6 to that result. Show the best way\n",
      "to calculate 0 × 33 × 0 × 55 using  shifts and adds/subtracts. Assume both\n",
      "inputs are 8-bit unsigned integers. 3.18 [20] <§3.4> Using a table similar to\n",
      "that shown in Figure 3.10, calculate  74 divided by 21 using the hardware\n",
      "described in Figure 3.8. You should show  the contents of each register on each\n",
      "step. Assume both inputs are unsigned 6-bit  integers. 3.19 [30] <§3.4> Using a\n",
      "table similar to that shown in Figure 3.10, calculate  74 divided by 21 using\n",
      "the hardware described in Figure 3.11. You should show  the contents of each\n",
      "register on each step. Assume A and B are unsigned 6-bit  integers.\n",
      "Page number: 333\n",
      "\n",
      "\n",
      "Score: 0.6631\n",
      "The shift right  in step 3 gives us the next bit of the multiplier to examine in\n",
      "the following iteration.  These three steps are repeated 64 times to obtain the\n",
      "product. If each step took a  clock cycle, this algorithm would require almost\n",
      "200 clock cycles to multiply two  64-bit numbers. The relative importance of\n",
      "arithmetic operations like multiply  varies with the program, but addition and\n",
      "subtraction may be anywhere from 5 to  100 times more popular than multiply.\n",
      "Accordingly, in many applications, multiply  can take several clock cycles\n",
      "without significantly affecting performance. However,  Amdahl’s Law (see Section\n",
      "1.10) reminds us that even a moderate frequency for a  slow operation can limit\n",
      "performance. This algorithm and hardware are easily refined to take one clock\n",
      "cycle per step.  The speed up comes from performing the operations in parallel:\n",
      "the multiplier  and multiplicand are shifted while the multiplicand is added to\n",
      "the product if the  multiplier bit is a 1. The hardware just has to ensure that\n",
      "it tests the right bit of  the multiplier and gets the preshifted version of the\n",
      "multiplicand. The hardware is  usually further optimized to halve the width of\n",
      "the adder and registers by noticing  where there are unused portions of\n",
      "registers and adders.\n",
      "Page number: 266\n",
      "\n",
      "\n",
      "Score: 0.6619\n",
      "Place 0 (0 × multiplicand) in the proper place if the digit is 0. Although the\n",
      "decimal example above happens to use only 0 and 1, multiplication  of binary\n",
      "numbers must always use 0 and 1, and thus always offers only these two  choices.\n",
      "Now that we have reviewed the basics of multiplication, the traditional next\n",
      "step is to provide the highly optimized multiply hardware. We break with\n",
      "tradition  in the belief that you will gain a better understanding by seeing the\n",
      "evolution of  the multiply hardware and algorithm through multiple generations.\n",
      "For now, let’s  assume that we are multiplying only positive numbers. Sequential\n",
      "Version of the Multiplication Algorithm   and Hardware This design mimics the\n",
      "algorithm we learned in grammar school; Figure 3.3 shows  the hardware. We have\n",
      "drawn the hardware so that data flow from top to bottom to  resemble more\n",
      "closely the paper-and-pencil method. Let’s assume that the multiplier is in the\n",
      "64-bit Multiplier register and that the  128-bit Product register is initialized\n",
      "to 0. From the paper-and-pencil example  above, it’s clear that we will need to\n",
      "move the multiplicand left one digit each step, as  it may be added to the\n",
      "intermediate products. Over 64 steps, a 64-bit multiplicand  would move 64 bits\n",
      "to the left.\n",
      "Page number: 265\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 6 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  8 20:07:49 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.40.06              Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...    On  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   58C    P0             41W /  127W |    1600MiB /   6144MiB |     27%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        30      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A      8775      C   /python3.12                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 6 | Recommended model: Gemma 2B in 4-bit precision.\n",
      "use_quantization_config set to: True\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5878f8ef709d483990214b6ed2ee5044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "\n",
    "if (is_flash_attn_2_available() and torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"\n",
    "\n",
    "model_id = model_id #gemma 2b it 4bit\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id, \n",
    "                                                 torch_dtype=torch.float16, \n",
    "                                                 quantization_config = quantization_config if use_quantization_config else None,\n",
    "                                                 attn_implementation = attn_implementation)\n",
    "\n",
    "if not use_quantization_config:\n",
    "    llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): GELUActivation()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm()\n",
       "        (post_attention_layernorm): GemmaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515268096"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 2106740736, 'model_mem_mb': 2009.14, 'model_mem_gb': 1.96}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What is a way to efficiently implement multiplication in assembly without a multiplication instruction?\n",
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "What is a way to efficiently implement multiplication in assembly without a multiplication instruction?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is a way to efficiently implement multiplication in assembly without a multiplication instruction?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[     2,      2,    106,   1645,    108,   1841,    603,    476,   1703,\n",
      "            577,  34790,   7133,  46824,    575,  14125,   2346,    476,  46824,\n",
      "          14239, 235336,    107,    108,    106,   2516,    108]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([     2,      2,    106,   1645,    108,   1841,    603,    476,   1703,\n",
      "           577,  34790,   7133,  46824,    575,  14125,   2346,    476,  46824,\n",
      "         14239, 235336,    107,    108,    106,   2516,    108,    688, 235274,\n",
      "        235265,  12266,   3298,   4977,   3228,    578,  24742,   3228,  66058,\n",
      "           109,   1917,  13119,    108,  11246, 235298,  11635, 235292,    108,\n",
      "           139,  11246,    548, 235274, 235269,    548, 235284, 235269,    548,\n",
      "        235304,    139, 235289,    548, 235274, 235269,    548, 235284, 235269,\n",
      "           578,    548, 235304,    708,    573,   2149,   5968,    577,  29686,\n",
      "           108,    139,    639,    548, 235274, 235269,    548, 235284, 235269,\n",
      "           548, 235304, 235269,    548, 235310,    139, 235289,    548, 235310,\n",
      "           603,    476,  17819,   7339,    108,    139, 123554,    548, 235274,\n",
      "        235269,    548, 235310, 235269,   3015,    139, 235289,  23547,   1013,\n",
      "           548, 235274,    603,    780,   6871,    577, 235248, 235276,    108,\n",
      "           139, 235312,  10007, 235298,   5542,    139, 235289,   1927,    783,\n",
      "          6378,   1517, 235269,    783, 235303,    478,   3015, 235269,    712,\n",
      "         13581,    108,    139,  11246,    548, 235274, 235269,    548, 235284,\n",
      "        235269,    548, 235304,    139, 235289,  44449,    573,  46824,    108,\n",
      "           139,   6709,    548, 235274, 235269,    548, 235284, 235269,    548,\n",
      "        235304,    139, 235289,  11209,    573,   2196,    575,   6884,    108,\n",
      "           139,  80451,    548, 235274, 235269,    548, 235274, 235269, 235248,\n",
      "        235274,    139, 235289, 122903,    548, 235274,    731, 235248, 235274,\n",
      "           604,    573,   2351,  40059,    108,    139, 235312,  10007, 235298,\n",
      "         11635,    139, 235289,  43630,    573,  10273,    108,   7262, 235292,\n",
      "           108,    139,  11246,    548, 235274, 235269,    548, 235284, 235269,\n",
      "           548, 235304,    139, 235289,  44449,    573,   2048,  46824,    108,\n",
      "           139,   6709,    548, 235274, 235269,    548, 235284, 235269,    548,\n",
      "        235304,    139, 235289,  11209,    573,   2196,    575,   6884,    108,\n",
      "           139,  27859,   9442,    139, 235289,  38155,    577,    573,    664,\n",
      "         18663, 235281,  14239,    108,  11246, 235298,   5542, 235292,    108,\n",
      "           139, 235289,   6698,    577,    614,  22315,   1452,    573,  46824,\n",
      "           108,    139, 235289,   2804,    108,  18663, 235292,    108,   1917,\n",
      "           109,    688], device='cuda:0')\n",
      "\n",
      "CPU times: user 11.4 s, sys: 1.36 s, total: 12.8 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<bos><bos><start_of_turn>user\n",
      "What is a way to efficiently implement multiplication in assembly without a multiplication instruction?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "**1. Using bitwise AND and logical AND:**\n",
      "\n",
      "```assembly\n",
      "mul_loop:\n",
      "  mul r1, r2, r3  ; r1, r2, and r3 are the three numbers to multiply\n",
      "  and r1, r2, r3, r4  ; r4 is a temporary register\n",
      "  bne r1, r4, done  ; Branch if r1 is not equal to 0\n",
      "  j mul_exit  ; If we reach here, we're done, so exit\n",
      "  mul r1, r2, r3  ; Perform the multiplication\n",
      "  store r1, r2, r3  ; Store the result in memory\n",
      "  addi r1, r1, 1  ; Increment r1 by 1 for the next iteration\n",
      "  j mul_loop  ; Repeat the loop\n",
      "done:\n",
      "  mul r1, r2, r3  ; Perform the final multiplication\n",
      "  store r1, r2, r3  ; Store the result in memory\n",
      "  jr finish  ; Jump to the \"finish\" instruction\n",
      "mul_exit:\n",
      "  ; Code to be executed after the multiplication\n",
      "  ; ...\n",
      "finish:\n",
      "```\n",
      "\n",
      "**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\n\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2253 embeddings: 0.00007 seconds.\n",
      "<bos><start_of_turn>user\n",
      "Based on the following context items, please answer the query.\n",
      "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
      "Don't return the thinking, only return the answer.\n",
      "Make sure your answers are as explanatory as possible.\n",
      "Use the following examples as reference for the ideal answer style.\n",
      "\n",
      "Example 1:\n",
      "Query: What are the fat-soluble vitamins?\n",
      "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
      "\n",
      "Example 2:\n",
      "Query: What are the causes of type 2 diabetes?\n",
      "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
      "\n",
      "Example 3:\n",
      "Query: What is the importance of hydration for physical performance?\n",
      "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
      "\n",
      "Now use the following context items to answer the user query:\n",
      "- 3.17 [20] <§3.3> As discussed in the text, one possible performance enhancement is  to do a shift and add instead of an actual multiplication. Since 9 × 6, for example, can  be written (2 × 2 × 2 + 1) × 6, we can calculate 9 × 6 by shifting 6 to the left three times  and then adding 6 to that result. Show the best way to calculate 0 × 33 × 0 × 55 using  shifts and adds/subtracts. Assume both inputs are 8-bit unsigned integers. 3.18 [20] <§3.4> Using a table similar to that shown in Figure 3.10, calculate  74 divided by 21 using the hardware described in Figure 3.8. You should show  the contents of each register on each step. Assume both inputs are unsigned 6-bit  integers. 3.19 [30] <§3.4> Using a table similar to that shown in Figure 3.10, calculate  74 divided by 21 using the hardware described in Figure 3.11. You should show  the contents of each register on each step. Assume A and B are unsigned 6-bit  integers.\n",
      "- Place 0 (0 × multiplicand) in the proper place if the digit is 0. Although the decimal example above happens to use only 0 and 1, multiplication  of binary numbers must always use 0 and 1, and thus always offers only these two  choices. Now that we have reviewed the basics of multiplication, the traditional next  step is to provide the highly optimized multiply hardware. We break with tradition  in the belief that you will gain a better understanding by seeing the evolution of  the multiply hardware and algorithm through multiple generations. For now, let’s  assume that we are multiplying only positive numbers. Sequential Version of the Multiplication Algorithm   and Hardware This design mimics the algorithm we learned in grammar school; Figure 3.3 shows  the hardware. We have drawn the hardware so that data flow from top to bottom to  resemble more closely the paper-and-pencil method. Let’s assume that the multiplier is in the 64-bit Multiplier register and that the  128-bit Product register is initialized to 0. From the paper-and-pencil example  above, it’s clear that we will need to move the multiplicand left one digit each step, as  it may be added to the intermediate products. Over 64 steps, a 64-bit multiplicand  would move 64 bits to the left.\n",
      "- A straightforward approach would be to connect the outputs of adders on the  right to the inputs of adders on the left, making a stack of adders 64 high. An  alternative way to organize these 64 additions is in a parallel tree, as Figure 3.7  shows. Instead of waiting for 64 add times, we wait just the log2 (64) or six 64-bit  add times. Product1 Product0 Product127 Product126 Product95..32 1 bit 1 bit 1 bit 1 bit . . . . . . . . . . . . . . . . . . 64 bits 64 bits 64 bits 64 bits 64 bits 64 bits 64 bits Mplier63 • Mcand Mplier62 • Mcand Mplier61 • Mcand Mplier60 • Mcand Mplier3 • Mcand Mplier2 • Mcand Mplier1 • Mcand Mplier0 • Mcand FIGURE 3.7 Fast multiplication hardware. Rather than use a single 64-bit adder 63 times, this hardware “unrolls the loop” to use 63  adders and then organizes them to minimize delay.\n",
      "- 250  Chapter 3 Arithmetic for Computers 3.13 [20] <§3.3> Using a table similar to that shown in Figure 3.6, calculate the  product of the hexadecimal unsigned 8-bit integers 62 and 12 using the hardware  described in Figure 3.5. You should show the contents of each register on each step. 3.14 [10] <§3.3> Calculate the time necessary to perform a multiply using the  approach given in Figures 3.3 and 3.4 if an integer is 8 bits wide and each step of  the operation takes four time units. Assume that in step 1a an addition is always  performed—either the multiplicand will be added, or a zero will be. Also assume  that the registers have already been initialized (you are just counting how long it  takes to do the multiplication loop itself). If this is being done in hardware, the  shifts of the multiplicand and multiplier can be done simultaneously. If this is being  done in software, they will have to be done one after the other. Solve for each case. 3.15 [10] <§3.3> Calculate the time necessary to perform a multiply using the  approach described in the text (31 adders stacked vertically) if an integer is 8 bits  wide and an adder takes four time units. 3.16 [20] <§3.3> Calculate the time necessary to perform a multiply using the  approach given in Figure 3.7 if an integer is 8 bits wide and an adder takes four  time units.\n",
      "- 3.3 Multiplication  193 Multiplicand Shift left 128 bits 128-bit ALU Product Write 128 bits Control test Multiplier Shift right 64 bits FIGURE 3.3 First version of the multiplication hardware. The Multiplicand register, ALU, and  Product register are all 128 bits wide, with only the Multiplier register containing 64 bits. ( Appendix A  describes ALUs.) The 64-bit multiplicand starts in the right half of the Multiplicand register and is shifted left  1 bit on each step. The multiplier is shifted in the opposite direction at each step. The algorithm starts with  the product initialized to 0. Control decides when to shift the Multiplicand and Multiplier registers and when  to write new values into the Product register. Figure 3.4 shows the three basic steps needed for each bit. The least significant  bit of the multiplier (Multiplier0) determines whether the multiplicand is added to  the Product register. The left shift in step 2 has the effect of moving the intermediate  operands to the left, just as when multiplying with paper and pencil.\n",
      "\n",
      "\n",
      "User query: What is a way to efficiently implement multiplication in assembly?\n",
      "Answer:<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query =\"What is a way to efficiently implement multiplication in assembly?\"\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "    \n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context_items)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is a way to efficiently implement multiplication in assembly?\n",
      "RAG answer:\n",
      "<bos>The passage provides a detailed explanation of different ways to achieve efficient multiplication, including a sequential version, a parallel tree, and a hardware design.\n",
      "\n",
      "**Sequential Version of the Multiplication Algorithm and Hardware**\n",
      "\n",
      "* The sequential version involves connecting outputs of adders on the right to inputs of adders on the left, forming a stack of adders 64 high.\n",
      "* This approach requires 64 iterations of adding the two operands.\n",
      "\n",
      "**Parallel Tree**\n",
      "\n",
      "* Another approach is to organize the 64 additions in a parallel tree structure.\n",
      "* By waiting for log2 (64) or six 64-bit additions, the hardware can perform the multiplication with optimal efficiency.\n",
      "\n",
      "**Hardware Design**\n",
      "\n",
      "* The hardware design utilizes an 8-bit multiplier and a 128-bit product register.\n",
      "* The multiplier is shifted left and right at each step to efficiently perform the multiplication.\n",
      "* This approach minimizes the number of adders used and reduces the number of control instructions.<eos>\n",
      "CPU times: user 10.4 s, sys: 1.33 s, total: 11.7 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=256) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2253 embeddings: 0.00011 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The passage does not explicitly describe how multiplication works in LEGV8, so I cannot answer this query from the context.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"how does multiplication work in legv8?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ask()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
